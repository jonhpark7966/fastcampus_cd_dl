{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26b62da5",
   "metadata": {},
   "source": [
    "# 슈카월드 컨텐츠를 기반으로 채팅하기\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6af1d4b",
   "metadata": {},
   "source": [
    "## Semantic Searching\n",
    "  - 데이터를 로드합니다.\n",
    "  - 질문의 Embedding 을 계산합니다.\n",
    "  - 계산된 Embedding 과 유사한 결과들을 탐색합니다.\n",
    "  - (참조) https://platform.openai.com/docs/guides/embeddings/what-are-embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff2282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c859dc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile_path = \"./data/shuka_embeddings.csv\"\n",
    "\n",
    "df = pd.read_csv(datafile_path)\n",
    "df[\"embedding\"] = df.embedding.apply(eval).apply(np.array)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f583ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "\n",
    "# 연관된 영상을 검색합니다.\n",
    "def search_video(df, product_description, n=3, pprint=True):\n",
    "    product_embedding = get_embedding(\n",
    "        product_description,\n",
    "        engine=\"text-embedding-ada-002\"\n",
    "    )\n",
    "    df[\"similarity\"] = df.embedding.apply(lambda x: cosine_similarity(x, product_embedding))\n",
    "\n",
    "    results = (\n",
    "        df.sort_values(\"similarity\", ascending=False)\n",
    "        .head(n)\n",
    "    )\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c08725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하고 싶은 말을 입력하고, 비슷한 결과들을 열람합니다.\n",
    "\n",
    "results = search_video(df, \"러시아와 우크라이나의 전쟁은 어떻게 되어가고 있나요?\", n=5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19425c36",
   "metadata": {},
   "source": [
    "## 검색 결과와 함께 질문하기!\n",
    "  - 질문과 유사한 컨텐츠를 검색합니다.\n",
    "  - GPT 의 프롬프트에 유사한 결과를 함께 넣어 줍니다.\n",
    "  - GPT 가 학습할 때 없었던 정보이지만, 이렇게 같이 넣어주면 GPT 가 누락되지 않은 정보를 이용하여 대답을 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e7455",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPT_MODEL=\"gpt-4\"\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def query_message(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    model: str,\n",
    "    token_budget: int\n",
    ") -> str:\n",
    "    \"\"\"Return a message for GPT, with relevant source texts pulled from a dataframe.\"\"\"\n",
    "    \n",
    "    results = search_video(df, query, n=5)\n",
    "    strings = results['combined']\n",
    "    \n",
    "    introduction = 'Use the below articles on the 슈카월드 to answer the subsequent question. If the answer cannot be found in the articles, write \"I could not find an answer.\"'\n",
    "    question = f\"\\n\\nQuestion: {query}\"\n",
    "    message = introduction\n",
    "    for string in strings:\n",
    "        next_article = f'\\n\\n:\\n\"\"\"\\n{string}\\n\"\"\"'\n",
    "        print(\"Tokens in Use : \", num_tokens(message + next_article + question, model=model))\n",
    "        if (\n",
    "            num_tokens(message + next_article + question, model=model)\n",
    "            > token_budget\n",
    "        ):\n",
    "            \n",
    "            break\n",
    "        else:\n",
    "            message += next_article\n",
    "    return message + question\n",
    "\n",
    "def ask(\n",
    "    query: str,\n",
    "    df: pd.DataFrame = df,\n",
    "    model: str = GPT_MODEL,\n",
    "    token_budget: int = 8192 - 500,\n",
    "    print_message: bool = False,\n",
    ") -> str:\n",
    "    \"\"\"Answers a query using GPT and a dataframe of relevant texts and embeddings.\"\"\"\n",
    "    message = query_message(query, df, model=model, token_budget=token_budget)\n",
    "    if print_message:\n",
    "        print(message)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You answer questions about 슈카의 유투브 내용\"},\n",
    "        {\"role\": \"user\", \"content\": message},\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0\n",
    "    )\n",
    "    response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return response_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0895310d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26034c9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28d9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set print_message=True to see the source text GPT was working off of\n",
    "ask('우크라이나와 러시아의 전쟁은 어떻게 되어가고 있나요?', model=\"gpt-4\", print_message=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
